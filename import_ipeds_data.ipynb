{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "from snowflake.connector import pandas_tools as pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_create_table(df, table_name):\n",
    "    # Mapping pandas dtypes to SQL types\n",
    "    dtype_mapping = {\n",
    "        'int64': 'INTEGER',\n",
    "        'float64': 'FLOAT',\n",
    "        'object': 'TEXT',\n",
    "        'datetime64[ns]': 'DATETIME',\n",
    "        'bool': 'BOOLEAN'\n",
    "    }\n",
    "\n",
    "    # Start of CREATE TABLE statement\n",
    "    sql = f\"CREATE OR REPLACE TABLE {table_name} (\\n\"\n",
    "\n",
    "    # Loop through DataFrame columns to define each column's SQL type\n",
    "    for col in df.columns:\n",
    "        col_dtype = str(df[col].dtype)\n",
    "        sql_type = dtype_mapping.get(col_dtype, 'TEXT')  # Default to TEXT if dtype not found\n",
    "        sql += f\"    {col} {sql_type},\\n\"\n",
    "\n",
    "    # Remove the trailing comma and newline, and add closing parenthesis\n",
    "    sql = sql.rstrip(',\\n') + \"\\n);\"\n",
    "    \n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_spaces(string_list):\n",
    "    return [ s.strip().replace('.', '_') if isinstance(s, str) else s for s in string_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =SUBSTITUTE(D2, D2, \", '\" &D2&\"'\") \n",
    "# to get formated file names, go to ipeds datacenter with complete datasets \n",
    "# copy the table with filenames into excel sheet\n",
    "# use the substitute function to format it for a python string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023 File Names\n",
    "ipeds_locs = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "yr = 2023\n",
    "ipeds_fils_list = [\n",
    " 'HD2023'\n",
    ", 'IC2023'\n",
    ", 'IC2023_AY'\n",
    ", 'IC2023_PY'\n",
    ", 'IC2023_CAMPUSES'\n",
    ", 'FLAGS2023'\n",
    ", 'EFFY2023'\n",
    ", 'EFFY2023_DIST'\n",
    ", 'EFFY2023_HS'\n",
    ", 'EFIA2023'\n",
    ", 'C2023_A'\n",
    ", 'C2023_B'\n",
    ", 'C2023_C'\n",
    ", 'C2023DEP'\n",
    ", 'DRVIC2023'\n",
    ", 'DRVEF122023'\n",
    ", 'DRVC2023'\n",
    "\n",
    "                   ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022 File Names\n",
    "yr = 2022\n",
    "ipeds_locs = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "ipeds_fils_list = [\n",
    "'HD2022'\n",
    ", 'IC2022'\n",
    "\n",
    ", 'IC2022_AY'\n",
    ", 'IC2022_PY'\n",
    ", 'IC2022_CAMPUSES'\n",
    ", 'FLAGS2022'\n",
    "\n",
    ", 'EFFY2022'\n",
    "\n",
    ", 'EFFY2022_DIST'\n",
    "\n",
    ", 'EFIA2022'\n",
    "\n",
    "\n",
    ", 'ADM2022'\n",
    ", 'EF2022A'\n",
    ", 'EF2022CP'\n",
    ", 'EF2022B'\n",
    ", 'EF2022C'\n",
    ", 'EF2022D'\n",
    ", 'EF2022A_DIST'\n",
    ", 'C2022_A'\n",
    "\n",
    ", 'C2022_B'\n",
    "\n",
    ", 'C2022_C'\n",
    "\n",
    ", 'C2022DEP'\n",
    "\n",
    "\n",
    ", 'SAL2022_IS'\n",
    ", 'SAL2022_NIS'\n",
    ", 'S2022_OC'\n",
    ", 'S2022_SIS'\n",
    ", 'S2022_IS'\n",
    ", 'S2022_NH'\n",
    ", 'EAP2022'\n",
    ", 'F2122_F1A'\n",
    ", 'F2122_F2'\n",
    ", 'F2122_F3'\n",
    ", 'SFA2122'\n",
    ", 'SFAV2122'\n",
    ", 'GR2022'\n",
    ", 'GR2022_L2'\n",
    ", 'GR2022_PELL_SSL'\n",
    ", 'GR200_22'\n",
    ", 'OM2022'\n",
    ", 'AL2022'\n",
    ", 'DRVIC2022'\n",
    ", 'DRVADM2022'\n",
    ", 'DRVEF2022'\n",
    ", 'DRVEF122022'\n",
    "\n",
    ", 'DRVC2022'\n",
    "\n",
    ", 'DRVGR2022'\n",
    ", 'DRVOM2022'\n",
    ", 'DRVF2022'\n",
    ", 'DRVHR2022'\n",
    ", 'DRVAL2022'\n",
    "\n",
    "\n",
    "                   ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021 File Names\n",
    "yr = 2021\n",
    "ipeds_locs = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "ipeds_fils_list = [\n",
    "'HD2021'\n",
    ", 'IC2021'\n",
    "\n",
    ", 'IC2021_AY'\n",
    ", 'IC2021_PY'\n",
    ", 'IC2021_CAMPUSES'\n",
    ", 'FLAGS2021'\n",
    "\n",
    ", 'EFFY2021'\n",
    "\n",
    ", 'EFFY2021_DIST'\n",
    "\n",
    ", 'EFIA2021'\n",
    "\n",
    "\n",
    ", 'ADM2021'\n",
    "\n",
    "\n",
    ", 'EF2021A'\n",
    "\n",
    ", 'EF2021B'\n",
    "\n",
    ", 'EF2021C'\n",
    "\n",
    ", 'EF2021D'\n",
    "\n",
    ", 'EF2021A_DIST'\n",
    "\n",
    ", 'C2021_A'\n",
    "\n",
    ", 'C2021_B'\n",
    "\n",
    ", 'C2021_C'\n",
    "\n",
    ", 'C2021DEP'\n",
    "\n",
    ", 'SAL2021_IS'\n",
    "\n",
    ", 'SAL2021_NIS'\n",
    "\n",
    ", 'S2021_OC'\n",
    "\n",
    ", 'S2021_SIS'\n",
    "\n",
    ", 'S2021_IS'\n",
    "\n",
    ", 'S2021_NH'\n",
    "\n",
    ", 'EAP2021'\n",
    "\n",
    ", 'F2021_F1A'\n",
    "\n",
    ", 'F2021_F2'\n",
    "\n",
    ", 'F2021_F3'\n",
    "\n",
    ", 'SFA2021'\n",
    "\n",
    ", 'SFAV2021'\n",
    "\n",
    ", 'GR2021'\n",
    "\n",
    ", 'GR2021_L2'\n",
    "\n",
    ", 'GR2021_PELL_SSL'\n",
    "\n",
    ", 'GR200_21'\n",
    "\n",
    ", 'OM2021'\n",
    "\n",
    ", 'AL2021'\n",
    "\n",
    ", 'DRVIC2021'\n",
    ", 'DRVADM2021'\n",
    "\n",
    ", 'DRVEF2021'\n",
    "\n",
    ", 'DRVEF122021'\n",
    "\n",
    ", 'DRVC2021'\n",
    "\n",
    ", 'DRVGR2021'\n",
    "\n",
    ", 'DRVOM2021'\n",
    "\n",
    ", 'DRVF2021'\n",
    "\n",
    ", 'DRVHR2021'\n",
    "\n",
    ", 'DRVAL2021'\n",
    "\n",
    "\n",
    "                   ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 File Names\n",
    "yr = 2020\n",
    "ipeds_locs = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "ipeds_fils_list = [\n",
    "'HD2020'\n",
    ", 'IC2020'\n",
    "\n",
    ", 'IC2020_AY'\n",
    ", 'IC2020_PY'\n",
    ", 'FLAGS2020'\n",
    "\n",
    ", 'EFFY2020'\n",
    "\n",
    ", 'EFFY2020_DIST'\n",
    "\n",
    ", 'EFIA2020'\n",
    "\n",
    ", 'ADM2020'\n",
    "\n",
    ", 'EF2020A'\n",
    "\n",
    ", 'EF2020CP'\n",
    "\n",
    ", 'EF2020B'\n",
    "\n",
    ", 'EF2020C'\n",
    "\n",
    ", 'EF2020D'\n",
    "\n",
    ", 'EF2020A_DIST'\n",
    "\n",
    ", 'C2020_A'\n",
    "\n",
    ", 'C2020_B'\n",
    "\n",
    ", 'C2020_C'\n",
    "\n",
    ", 'C2020DEP'\n",
    "\n",
    ", 'SAL2020_IS'\n",
    "\n",
    ", 'SAL2020_NIS'\n",
    "\n",
    ", 'S2020_OC'\n",
    "\n",
    ", 'S2020_SIS'\n",
    "\n",
    ", 'S2020_IS'\n",
    "\n",
    ", 'S2020_NH'\n",
    "\n",
    ", 'EAP2020'\n",
    "\n",
    ", 'F1920_F1A'\n",
    "\n",
    ", 'F1920_F2'\n",
    "\n",
    ", 'F1920_F3'\n",
    "\n",
    ", 'SFA1920'\n",
    "\n",
    ", 'SFAV1920'\n",
    "\n",
    ", 'GR2020'\n",
    "\n",
    ", 'GR2020_L2'\n",
    "\n",
    ", 'GR2020_PELL_SSL'\n",
    "\n",
    ", 'GR200_20'\n",
    "\n",
    ", 'OM2020'\n",
    "\n",
    ", 'AL2020'\n",
    "                   ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 File Names\n",
    "yr = 2019\n",
    "ipeds_locs = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "ipeds_fils_list = [\n",
    "\n",
    "'HD2019'\n",
    ", 'IC2019'\n",
    "\n",
    ", 'IC2019_AY'\n",
    ", 'IC2019_PY'\n",
    ", 'FLAGS2019'\n",
    "\n",
    ", 'EFFY2019'\n",
    "\n",
    ", 'EFIA2019'\n",
    "\n",
    ", 'ADM2019'\n",
    "\n",
    ", 'EF2019A'\n",
    "\n",
    ", 'EF2019B'\n",
    "\n",
    ", 'EF2019C'\n",
    "\n",
    ", 'EF2019D'\n",
    "\n",
    ", 'EF2019A_DIST'\n",
    "\n",
    ", 'C2019_A'\n",
    "\n",
    ", 'C2019_B'\n",
    "\n",
    ", 'C2019_C'\n",
    "\n",
    ", 'C2019DEP'\n",
    "\n",
    ", 'SAL2019_IS'\n",
    "\n",
    ", 'SAL2019_NIS'\n",
    "\n",
    ", 'S2019_OC'\n",
    "\n",
    ", 'S2019_SIS'\n",
    "\n",
    ", 'S2019_IS'\n",
    "\n",
    ", 'S2019_NH'\n",
    "\n",
    ", 'EAP2019'\n",
    "\n",
    ", 'F1819_F1A'\n",
    "\n",
    ", 'F1819_F2'\n",
    "\n",
    ", 'F1819_F3'\n",
    "\n",
    ", 'SFA1819'\n",
    "\n",
    ", 'SFAV1819'\n",
    "\n",
    ", 'GR2019'\n",
    "\n",
    ", 'GR2019_L2'\n",
    "\n",
    ", 'GR2019_PELL_SSL'\n",
    "\n",
    ", 'GR200_19'\n",
    "\n",
    ", 'OM2019'\n",
    "\n",
    ", 'AL2019'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 File Names\n",
    "yr = 2018\n",
    "ipeds_locs = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "ipeds_fils_list = [\n",
    "\n",
    "'HD2018'\n",
    ", 'IC2018'\n",
    ",'FLAGS2018'\n",
    ", 'IC2018_AY'\n",
    ", 'IC2018_PY'\n",
    "\n",
    ", 'EFFY2018'\n",
    "\n",
    ", 'EFIA2018'\n",
    "\n",
    ", 'ADM2018'\n",
    "\n",
    ", 'EF2018A'\n",
    "\n",
    ", 'EF2018CP'\n",
    "\n",
    ", 'EF2018B'\n",
    "\n",
    ", 'EF2018C'\n",
    "\n",
    ", 'EF2018D'\n",
    "\n",
    ", 'EF2018A_DIST'\n",
    "\n",
    ", 'C2018_A'\n",
    "\n",
    ", 'C2018_B'\n",
    "\n",
    ", 'C2018_C'\n",
    "\n",
    ", 'C2018DEP'\n",
    "\n",
    ", 'SAL2018_IS'\n",
    "\n",
    ", 'SAL2018_NIS'\n",
    "\n",
    ", 'S2018_OC'\n",
    "\n",
    ", 'S2018_SIS'\n",
    "\n",
    ", 'S2018_IS'\n",
    "\n",
    ", 'S2018_NH'\n",
    "\n",
    ", 'EAP2018'\n",
    "\n",
    ", 'F1718_F1A'\n",
    "\n",
    ", 'F1718_F2'\n",
    "\n",
    ", 'F1718_F3'\n",
    "\n",
    ", 'SFA1718'\n",
    "\n",
    ", 'SFAV1718'\n",
    "\n",
    ", 'GR2018'\n",
    "\n",
    ", 'GR2018_L2'\n",
    "\n",
    ", 'GR2018_PELL_SSL'\n",
    "\n",
    ", 'GR200_18'\n",
    "\n",
    ", 'OM2018'\n",
    "\n",
    ", 'AL2018'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017 File Names\n",
    "yr = 2017\n",
    "ipeds_locs = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "ipeds_fils_list = [\n",
    "'HD2017'\n",
    ", 'IC2017'\n",
    ",'FLAGS2017'\n",
    ", 'IC2017_AY'\n",
    ", 'IC2017_PY'\n",
    "\n",
    ", 'EFFY2017'\n",
    "\n",
    ", 'EFIA2017'\n",
    "\n",
    ", 'ADM2017'\n",
    "\n",
    ", 'EF2017A'\n",
    "\n",
    ", 'EF2017B'\n",
    "\n",
    ", 'EF2017C'\n",
    "\n",
    ", 'EF2017D'\n",
    "\n",
    ", 'EF2017A_DIST'\n",
    "\n",
    ", 'C2017_A'\n",
    "\n",
    ", 'C2017_B'\n",
    "\n",
    ", 'C2017_C'\n",
    "\n",
    ", 'C2017DEP'\n",
    "\n",
    ", 'SAL2017_IS'\n",
    "\n",
    ", 'SAL2017_NIS'\n",
    "\n",
    ", 'S2017_OC'\n",
    "\n",
    ", 'S2017_SIS'\n",
    "\n",
    ", 'S2017_IS'\n",
    "\n",
    ", 'S2017_NH'\n",
    "\n",
    ", 'EAP2017'\n",
    "\n",
    ", 'F1617_F1A'\n",
    "\n",
    ", 'F1617_F2'\n",
    "\n",
    ", 'F1617_F3'\n",
    "\n",
    ", 'SFA1617'\n",
    "\n",
    ", 'SFAV1617'\n",
    "\n",
    ", 'GR2017'\n",
    "\n",
    ", 'GR2017_L2'\n",
    "\n",
    ", 'GR2017_PELL_SSL'\n",
    "\n",
    ", 'GR200_17'\n",
    "\n",
    ", 'OM2017'\n",
    "\n",
    ", 'AL2017'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016 File Names\n",
    "yr = 2016\n",
    "ipeds_locs = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "ipeds_fils_list = [\n",
    "'HD2016'\n",
    ", 'IC2016'\n",
    ",'FLAGS2016'\n",
    ", 'IC2016_AY'\n",
    ", 'IC2016_PY'\n",
    ", 'EFFY2016'\n",
    "\n",
    ", 'EFIA2016'\n",
    "\n",
    ", 'ADM2016'\n",
    "\n",
    ", 'EF2016A'\n",
    "\n",
    ", 'EF2016CP'\n",
    "\n",
    ", 'EF2016B'\n",
    "\n",
    ", 'EF2016C'\n",
    "\n",
    ", 'EF2016D'\n",
    "\n",
    ", 'EF2016A_DIST'\n",
    "\n",
    ", 'C2016_A'\n",
    "\n",
    ", 'C2016_B'\n",
    "\n",
    ", 'C2016_C'\n",
    "\n",
    ", 'C2016DEP'\n",
    "\n",
    ", 'SAL2016_IS'\n",
    "\n",
    ", 'SAL2016_NIS'\n",
    "\n",
    ", 'S2016_OC'\n",
    "\n",
    ", 'S2016_SIS'\n",
    "\n",
    ", 'S2016_IS'\n",
    "\n",
    ", 'S2016_NH'\n",
    "\n",
    ", 'EAP2016'\n",
    "\n",
    ", 'F1516_F1A'\n",
    "\n",
    ", 'F1516_F2'\n",
    "\n",
    ", 'F1516_F3'\n",
    "\n",
    ", 'SFA1516'\n",
    "\n",
    ", 'SFAV1516'\n",
    "\n",
    ", 'GR2016'\n",
    "\n",
    ", 'GR2016_L2'\n",
    "\n",
    ", 'GR2016_PELL_SSL'\n",
    "\n",
    ", 'GR200_16'\n",
    "\n",
    ", 'OM2016'\n",
    "\n",
    ", 'AL2016'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015 File Names\n",
    "yr = 2015\n",
    "ipeds_locs = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "ipeds_fils_list = [\n",
    "'HD2015'\n",
    ", 'IC2015'\n",
    "\n",
    ", 'IC2015_AY'\n",
    ", 'IC2015_PY'\n",
    "\n",
    ", 'EFFY2015'\n",
    "\n",
    ", 'EFIA2015'\n",
    "\n",
    ", 'ADM2015'\n",
    "\n",
    ", 'EF2015A'\n",
    "\n",
    ", 'EF2015B'\n",
    "\n",
    ", 'EF2015C'\n",
    "\n",
    ", 'EF2015D'\n",
    "\n",
    ", 'EF2015A_DIST'\n",
    "\n",
    ", 'C2015_A'\n",
    "\n",
    ", 'C2015_B'\n",
    "\n",
    ", 'C2015_C'\n",
    "\n",
    ", 'C2015DEP'\n",
    "\n",
    ", 'SAL2015_IS'\n",
    "\n",
    ", 'SAL2015_NIS'\n",
    "\n",
    ", 'S2015_OC'\n",
    "\n",
    ", 'S2015_SIS'\n",
    "\n",
    ", 'S2015_IS'\n",
    "\n",
    ", 'S2015_NH'\n",
    "\n",
    ", 'EAP2015'\n",
    "\n",
    ", 'F1415_F1A'\n",
    "\n",
    ", 'F1415_F2'\n",
    "\n",
    ", 'F1415_F3'\n",
    "\n",
    ", 'SFA1415'\n",
    "\n",
    ", 'SFAV1415'\n",
    "\n",
    ", 'GR2015'\n",
    "\n",
    ", 'GR2015_L2'\n",
    "\n",
    ", 'GR200_15'\n",
    "\n",
    ", 'FLAGS2015'\n",
    "\n",
    ", 'OM2015'\n",
    "\n",
    ", 'AL2015'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014 File Names\n",
    "yr = 2014\n",
    "ipeds_locs = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "ipeds_fils_list = [\n",
    "\n",
    "'HD2014'\n",
    ", 'IC2014'\n",
    "\n",
    ", 'IC2014_AY'\n",
    ", 'IC2014_PY'\n",
    "\n",
    ",'FLAGS2014'\n",
    "\n",
    ", 'EFFY2014'\n",
    "\n",
    ", 'EFIA2014'\n",
    "\n",
    ", 'ADM2014'\n",
    "\n",
    ", 'EF2014A'\n",
    "\n",
    ", 'EF2014CP'\n",
    "\n",
    ", 'EF2014B'\n",
    "\n",
    ", 'EF2014C'\n",
    "\n",
    ", 'EF2014D'\n",
    "\n",
    ", 'EF2014A_DIST'\n",
    "\n",
    ", 'C2014_A'\n",
    "\n",
    ", 'C2014_B'\n",
    "\n",
    ", 'C2014_C'\n",
    "\n",
    ", 'C2014DEP'\n",
    "\n",
    ", 'SAL2014_IS'\n",
    "\n",
    ", 'SAL2014_NIS'\n",
    "\n",
    ", 'S2014_OC'\n",
    "\n",
    ", 'S2014_SIS'\n",
    "\n",
    ", 'S2014_IS'\n",
    "\n",
    ", 'S2014_NH'\n",
    "\n",
    ", 'EAP2014'\n",
    "\n",
    ", 'F1314_F1A'\n",
    "\n",
    ", 'F1314_F2'\n",
    "\n",
    ", 'F1314_F3'\n",
    "\n",
    ", 'SFA1314'\n",
    "\n",
    ", 'SFAV1314'\n",
    "\n",
    ", 'GR2014'\n",
    "\n",
    ", 'GR2014_L2'\n",
    "\n",
    ", 'GR200_14'\n",
    "\n",
    ", 'AL2014'\n",
    "\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2013 File Names\n",
    "yr = 2013\n",
    "ipeds_locs = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "ipeds_fils_list = [\n",
    "'HD2013'\n",
    ", 'IC2013'\n",
    "\n",
    ", 'IC2013_AY'\n",
    ", 'IC2013_PY'\n",
    ", 'FLAGS2013'\n",
    "\n",
    ", 'EFFY2013'\n",
    "\n",
    ", 'EFIA2013'\n",
    "\n",
    ", 'IC2013'\n",
    "\n",
    ", 'EF2013A'\n",
    "\n",
    ", 'EF2013B'\n",
    "\n",
    ", 'EF2013C'\n",
    "\n",
    ", 'EF2013D'\n",
    "\n",
    ", 'EF2013A_DIST'\n",
    "\n",
    ", 'C2013_A'\n",
    "\n",
    ", 'C2013_B'\n",
    "\n",
    ", 'C2013_C'\n",
    "\n",
    ", 'C2013DEP'\n",
    "\n",
    ", 'SAL2013_IS'\n",
    "\n",
    ", 'SAL2013_NIS'\n",
    "\n",
    ", 'S2013_OC'\n",
    "\n",
    ", 'S2013_SIS'\n",
    "\n",
    ", 'S2013_IS'\n",
    "\n",
    ", 'S2013_NH'\n",
    "\n",
    ", 'EAP2013'\n",
    "\n",
    ", 'F1213_F1A'\n",
    "\n",
    ", 'F1213_F2'\n",
    "\n",
    ", 'F1213_F3'\n",
    "\n",
    ", 'SFA1213'\n",
    "\n",
    ", 'GR2013'\n",
    "\n",
    ", 'GR2013_L2'\n",
    "\n",
    ", 'GR200_13'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ipeds_fils in ipeds_fils_list:\n",
    "    print('GETTING FILES FROM {}'.format(yr))\n",
    "    rdata = requests.get(ipeds_locs + ipeds_fils.format(yr) + '.zip')\n",
    "    rdata_zip = zipfile.ZipFile(io.BytesIO(rdata.content))\n",
    "\n",
    "    print('Extracting {} files from zip archive:'.format(yr))\n",
    "    rdata_zip.printdir()\n",
    "    rdata_zip.extractall(path='{}_data'.format(yr))\n",
    "\n",
    "    print('Saving zip archive to disk.')\n",
    "    open('{}_data/'.format(yr) + ipeds_fils.format(yr) + '.zip', 'wb').write(rdata.content)\n",
    "    \n",
    "\n",
    "    ### Comment below out to make sure files exists and run correctly before sending to snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgallegos5\\AppData\\Roaming\\Python\\Python311\\site-packages\\snowflake\\connector\\config_manager.py:351: UserWarning: Bad owner or permissions on C:\\Users\\jgallegos5\\AppData\\Local\\snowflake\\connections.toml\n",
      "  warn(f\"Bad owner or permissions on {str(filep)}{chmod_message}\")\n"
     ]
    }
   ],
   "source": [
    "# Need to connect to the correct schema before pushing data again\n",
    "### snowflake will look for myconnection in C:\\Users\\user_name\\AppData\\Local\\Snowflake\\myconnection.toml\n",
    "# create new if needed\n",
    "import snowflake.connector\n",
    "con = snowflake.connector.connect(\n",
    "      connection_name=\"myconnection\",\n",
    "      schema='IPEDS_{}'.format(yr),\n",
    "      database=\"IPEDS_DEV\"\n",
    ")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepping Data\n",
      "Creating table HD2017\n",
      "Adding HD2017 data\n",
      "Prepping Data\n",
      "Creating table IC2017_RV\n",
      "Adding IC2017_RV data\n",
      "Prepping Data\n",
      "Creating table FLAGS2017\n",
      "Adding FLAGS2017 data\n",
      "Prepping Data\n",
      "Creating table IC2017_AY\n",
      "Adding IC2017_AY data\n",
      "Prepping Data\n",
      "Creating table IC2017_PY\n",
      "Adding IC2017_PY data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgallegos5\\AppData\\Local\\Temp\\ipykernel_35904\\1034093624.py:45: UserWarning: Pandas Dataframe has non-standard index of type <class 'pandas.core.indexes.base.Index'> which will not be written. Consider changing the index to pd.RangeIndex(start=0,...,step=1) or call reset_index() to keep index as column(s)\n",
      "  pt.write_pandas(conn=con, df=df, table_name=table_name, database='IPEDS_DEV', schema='IPEDS_{}'.format(yr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepping Data\n",
      "Creating table EFFY2017_RV\n",
      "Adding EFFY2017_RV data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for ipeds_fils in ipeds_fils_list:\n",
    "    ipeds_fils = ipeds_fils.upper()\n",
    "    ipeds_fils_rv = ipeds_fils + '_RV'\n",
    "    if os.path.exists('{}_data/'.format(yr) + ipeds_fils_rv.format(yr) + '.csv'):\n",
    "        \n",
    "        print('Prepping Data')\n",
    "        df = pd.read_csv('{}_data/'.format(yr) + ipeds_fils_rv.format(yr) + '.csv', \n",
    "                        encoding='ISO-8859-1')\n",
    "        # Some columns have trailing or leading spaces which will mess up \n",
    "        # sending data to snowflake\n",
    "        # Also get rid of duplicate columns\n",
    "        df.columns = strip_spaces(df.columns) #add column AY 2021 to 2022\n",
    "        table_name = ipeds_fils_rv.format(yr)\n",
    "        create_table_sql = generate_sql_create_table(df, table_name)\n",
    "\n",
    "        ### Comment below out to make sure files exists and run correctly before sending to snowflake\n",
    "        print('Creating table {}'.format(table_name))\n",
    "        #print(create_table_sql)\n",
    "        cur.execute(create_table_sql)\n",
    "        \n",
    "        # Drop non _rv table\n",
    "        cur.execute('DROP TABLE IF EXISTS {};'.format(ipeds_fils))\n",
    "        # cur.execute(create_table_sql)\n",
    "        print('Adding {} data'.format(table_name))\n",
    "        pt.write_pandas(conn=con, df=df, table_name=table_name, database='IPEDS_DEV', schema='IPEDS_{}'.format(yr))\n",
    "\n",
    "    else:\n",
    "        print('Prepping Data')\n",
    "        df = pd.read_csv('{}_data/'.format(yr) + ipeds_fils.format(yr) + '.csv', \n",
    "                        encoding='ISO-8859-1')\n",
    "        # Some columns have trailing or leading spaces which will mess up \n",
    "        # sending data to snowflake\n",
    "        # Also get rid of duplicate columns\n",
    "        df.columns = strip_spaces(df.columns) #add column AY 2021 to 2022\n",
    "        table_name = ipeds_fils.format(yr).upper()\n",
    "        create_table_sql = generate_sql_create_table(df, table_name)\n",
    "\n",
    "        ### Comment below out to make sure files exists and run correctly before sending to snowflake\n",
    "        print('Creating table {}'.format(table_name))\n",
    "        #print(create_table_sql)\n",
    "        cur.execute(create_table_sql)\n",
    "\n",
    "        print('Adding {} data'.format(table_name))\n",
    "        pt.write_pandas(conn=con, df=df, table_name=table_name, database='IPEDS_DEV', schema='IPEDS_{}'.format(yr))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all years into one table into Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_spaces(string_list):\n",
    "    return [ s.strip().replace('.', '_') if isinstance(s, str) else s for s in string_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_column(df):\n",
    "    \"\"\"\n",
    "    This function checks if a column contains any '.' values, \n",
    "    replaces them with 0, and converts the column to float.\n",
    "    \"\"\"\n",
    "    for column_name in df.columns:\n",
    "        # Check if the column contains any '.'\n",
    "        if df[column_name].isin(['.']).any():\n",
    "            # Replace '.' with 0\n",
    "            df[column_name] = df[column_name].replace('.', 0)\n",
    "            \n",
    "            # Convert the column to float\n",
    "            df[column_name] = df[column_name].astype(float)\n",
    "    # OPEID has emtpy spaces and SF wont convert to string object, need everything\n",
    "    # to be an integer\n",
    "        if column_name == 'OPEID':\n",
    "            # Regex pattern to match anything that's not a positive/negative integer\n",
    "            pattern = r'^(?![-+]?\\d+$).*$'\n",
    "            df[column_name] = df[column_name].replace(to_replace=pattern, value='-2', regex=True)\n",
    "            df[column_name] = df[column_name].astype(int)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def align_columns(df1, df2):\n",
    "    # Get columns in both DataFrames\n",
    "    df1.columns = strip_spaces(df1.columns)\n",
    "    df2.columns = strip_spaces(df2.columns)\n",
    "    df1_cols = df1.columns\n",
    "    df2_cols = df2.columns\n",
    "\n",
    "    # Find columns missing in df1 that are present in df2\n",
    "    missing_in_df1 = df2_cols.difference(df1_cols)\n",
    "    # Find columns missing in df2 that are present in df1\n",
    "    missing_in_df2 = df1_cols.difference(df2_cols)\n",
    "\n",
    "    # Add missing columns to df1, filled with NaN\n",
    "    for col in missing_in_df1:\n",
    "        df1[col] = np.nan\n",
    "\n",
    "    # Add missing columns to df2, filled with NaN\n",
    "    for col in missing_in_df2:\n",
    "        df2[col] = np.nan\n",
    "\n",
    "    # Ensure the same column order for both DataFrames\n",
    "    df1 = df1[df2.columns]\n",
    "    \n",
    "    return df1, df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "def union_file_years(regex, starting_year=2017):\n",
    "    \n",
    "    years = list(range(starting_year, datetime.datetime.now().year + 1))\n",
    "    pattern = re.compile(regex)\n",
    "    # pattern = re.compile(regex)\n",
    "    all_df = pd.DataFrame()\n",
    "    for year in years:\n",
    "        search_dir = str(year) + '_data'\n",
    "        # Get all CSV files in the directory\n",
    "        csv_files = glob.glob(os.path.join(search_dir, \"*.csv\"))\n",
    "        rv = False\n",
    "        # Filter files that match the pattern\n",
    "        matched_files = [file for file in csv_files if pattern.search(os.path.basename(file))]\n",
    "        # print('list',matched_files)\n",
    "        for file in matched_files:\n",
    "            if '_rv' in file:\n",
    "                rv = True\n",
    "                print(file)\n",
    "                new_df = pd.read_csv(file, encoding='latin')\n",
    "                new_df = clean_column(new_df)\n",
    "                new_df['COLLECTION'] = str(year)+'_rv' \n",
    "                if not all_df.empty:\n",
    "                    new_df, all_df = align_columns(new_df, all_df)\n",
    "                    all_df = pd.concat([new_df, all_df])\n",
    "                else:\n",
    "                    all_df = new_df\n",
    "                        \n",
    "        # Print matched files\n",
    "        if not rv and len(matched_files) != 0:\n",
    "            file = matched_files[0]\n",
    "            print(file)\n",
    "            new_df = pd.read_csv(file, encoding='latin')\n",
    "            new_df = clean_column(new_df)\n",
    "            new_df['COLLECTION'] = str(year)\n",
    "            if not all_df.empty:\n",
    "                new_df, all_df = align_columns(new_df, all_df)\n",
    "                all_df = pd.concat([new_df, all_df])\n",
    "            else:\n",
    "                all_df = new_df\n",
    "    return all_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_create_table(df, table_name):\n",
    "    # Mapping pandas dtypes to SQL types\n",
    "    dtype_mapping = {\n",
    "        'int64': 'INTEGER',\n",
    "        'float64': 'FLOAT',\n",
    "        'object': 'TEXT',\n",
    "        'datetime64[ns]': 'DATETIME',\n",
    "        'bool': 'BOOLEAN'\n",
    "    }\n",
    "\n",
    "    # Start of CREATE TABLE statement\n",
    "    sql = f\"CREATE OR REPLACE TABLE {table_name} (\\n\"\n",
    "\n",
    "    # Loop through DataFrame columns to define each column's SQL type\n",
    "    for col in df.columns:\n",
    "        # print(col)\n",
    "        col_dtype = str(df[col].dtype)\n",
    "        sql_type = dtype_mapping.get(col_dtype, 'TEXT')  # Default to TEXT if dtype not found\n",
    "        sql += f\"    {col} {sql_type},\\n\"\n",
    "\n",
    "    # Remove the trailing comma and newline, and add closing parenthesis\n",
    "    sql = sql.rstrip(',\\n') + \"\\n);\"\n",
    "    \n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_names = {\n",
    "'admyear': r'^adm20\\d{2}(_rv)?\\.csv$'\n",
    ",'alyear': r'^al20\\d{2}(_rv)?\\.csv$'\n",
    ",'cyear_a': r'^c20\\d{2}_a(_rv)?\\.csv$'\n",
    ",'cyear_b': r'^c20\\d{2}_b(_rv)?\\.csv$'\n",
    ",'cyear_c': r'^c20\\d{2}_c(_rv)?\\.csv$'\n",
    ",'cyeardep': r'^c20\\d{2}dep(_rv)?\\.csv$'\n",
    ",'drvadmyear': r'^drvadm20\\d{2}(_rv)?\\.csv$'\n",
    ",'drvcyear': r'^drvc20\\d{2}(_rv)?\\.csv$'\n",
    ",'drvef12year': r'^drvef1220\\d{2}(_rv)?\\.csv$'\n",
    ",'drvefyear': r'^drvef20\\d{2}(_rv)?\\.csv$'\n",
    ",'drvhryear': r'^drvhr20\\d{2}(_rv)?\\.csv$'\n",
    ",'drvicyear': r'^drvic20\\d{2}(_rv)?\\.csv$'\n",
    ",'drvomyear': r'^drvom20\\d{2}(_rv)?\\.csv$'\n",
    ",'eapyear': r'^eap\\d{4}(_rv)?\\.csv$'\n",
    ",'effyyear': r'^effy20\\d{2}(_rv)?\\.csv$'\n",
    ",'effyyear_dist': r'^effy20\\d{2}_dist(_rv)?\\.csv$'\n",
    ",'effyyear_hs': r'^effy20\\d{2}_hs(_rv)?\\.csv$'\n",
    ",'efiayear': r'^efia20\\d{2}(_rv)?\\.csv$'\n",
    ",'efyeara': r'^ef20\\d{2}a(_rv)?\\.csv$'\n",
    ",'efyeara_dist': r'^ef20\\d{2}a_dist(_rv)?\\.csv$'\n",
    ",'efyearb': r'^ef20\\d{2}b(_rv)?\\.csv$'\n",
    ",'efyearc': r'^ef20\\d{2}c(_rv)?\\.csv$'\n",
    ",'efyearcp': r'^ef20\\d{2}cp(_rv)?\\.csv$'\n",
    ",'efyeard': r'^ef20\\d{2}d(_rv)?\\.csv$'\n",
    ",'flagsyear': r'^flags20\\d{2}(_rv)?\\.csv$'\n",
    ",'fyryr_f1a': r'^f\\d{4}_f1a(_rv)?\\.csv$'\n",
    ",'fyryr_f2': r'^f\\d{4}_f2(_rv)?\\.csv$'\n",
    ",'fyryr_f3': r'^f\\d{4}_f3(_rv)?\\.csv$'\n",
    ",'gr200_yr': r'^gr200_\\d{2}(_rv)?\\.csv$'\n",
    ",'gryear': r'^gr20\\d{2}(_rv)?\\.csv$'\n",
    ",'gryear_l2': r'^gr20\\d{2}_l2(_rv)?\\.csv$'\n",
    ",'gryear_pell_ssl': r'^gr20\\d{2}_pell_ssl(_rv)?\\.csv$'\n",
    ",'hdsalyear_nis': r'^sal20\\d{2}_nis(_rv)?\\.csv$'\n",
    ",'hdyear': r'^hd20\\d{2}(_rv)?\\.csv$'\n",
    ",'icyear': r'^ic20\\d{2}(_rv)?\\.csv$'\n",
    ",'icyear_ay': r'^ic20\\d{2}_ay(_rv)?\\.csv$'\n",
    ",'icyear_campuses': r'^ic20\\d{2}_campuses(_rv)?\\.csv$'\n",
    ",'icyear_py': r'^ic20\\d{2}_py(_rv)?\\.csv$'\n",
    ",'omyear': r'^om20\\d{2}(_rv)?\\.csv$'\n",
    ",'salyear_is': r'^sal20\\d{2}_is(_rv)?\\.csv$'\n",
    ",'salyear_nis': r'^sal20\\d{2}_nis(_rv)?\\.csv$'\n",
    ",'sfavyear': r'^sfav\\d{4}(_rv)?\\.csv$'\n",
    ",'sfayear': r'^sfa\\d{4}(_rv)?\\.csv$'\n",
    ",'syear_is': r'^s\\d{4}_is(_rv)?\\.csv$'\n",
    ",'syear_nh': r'^s20\\d{2}_nh(_rv)?\\.csv$'\n",
    ",'syear_oc': r'^s20\\d{2}_oc(_rv)?\\.csv$'\n",
    ",'syear_sis': r'^s20\\d{2}_sis(_rv)?\\.csv$'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgallegos5\\AppData\\Roaming\\Python\\Python311\\site-packages\\snowflake\\connector\\config_manager.py:351: UserWarning: Bad owner or permissions on C:\\Users\\jgallegos5\\AppData\\Local\\snowflake\\connections.toml\n",
      "  warn(f\"Bad owner or permissions on {str(filep)}{chmod_message}\")\n"
     ]
    }
   ],
   "source": [
    "# Need to connect to the correct schema before pushing data again\n",
    "### snowflake will look for myconnection in C:\\Users\\user_name\\AppData\\Local\\Snowflake\\myconnection.toml\n",
    "# create new if needed\n",
    "import snowflake.connector\n",
    "from snowflake.connector import pandas_tools as pt\n",
    "con = snowflake.connector.connect(\n",
    "      connection_name=\"myconnection\",\n",
    "      schema='IPEDS_ALL_YEARS',\n",
    "      database=\"IPEDS_DEV\"\n",
    ")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017_data\\sal2017_nis_rv.csv\n",
      "2018_data\\sal2018_nis_rv.csv\n",
      "2019_data\\sal2019_nis_rv.csv\n",
      "2020_data\\sal2020_nis_rv.csv\n",
      "2021_data\\sal2021_nis_rv.csv\n",
      "2022_data\\sal2022_nis.csv\n",
      "Creating table SALYEAR_NIS\n",
      "CREATE OR REPLACE TABLE SALYEAR_NIS (\n",
      "    UNITID INTEGER,\n",
      "    XSANIN01 TEXT,\n",
      "    SANIN01 INTEGER,\n",
      "    XSANIT01 TEXT,\n",
      "    SANIT01 FLOAT,\n",
      "    XSANIN02 TEXT,\n",
      "    SANIN02 INTEGER,\n",
      "    XSANIT02 TEXT,\n",
      "    SANIT02 FLOAT,\n",
      "    XSANIN03 TEXT,\n",
      "    SANIN03 INTEGER,\n",
      "    XSANIT03 TEXT,\n",
      "    SANIT03 FLOAT,\n",
      "    XSANIN04 TEXT,\n",
      "    SANIN04 INTEGER,\n",
      "    XSANIT04 TEXT,\n",
      "    SANIT04 FLOAT,\n",
      "    XSANIN05 TEXT,\n",
      "    SANIN05 INTEGER,\n",
      "    XSANIT05 TEXT,\n",
      "    SANIT05 FLOAT,\n",
      "    XSANIN06 TEXT,\n",
      "    SANIN06 INTEGER,\n",
      "    XSANIT06 TEXT,\n",
      "    SANIT06 FLOAT,\n",
      "    XSANIN07 TEXT,\n",
      "    SANIN07 INTEGER,\n",
      "    XSANIT07 TEXT,\n",
      "    SANIT07 FLOAT,\n",
      "    XSANIN08 TEXT,\n",
      "    SANIN08 INTEGER,\n",
      "    XSANIT08 TEXT,\n",
      "    SANIT08 FLOAT,\n",
      "    XSANIN09 TEXT,\n",
      "    SANIN09 INTEGER,\n",
      "    XSANIT09 TEXT,\n",
      "    SANIT09 FLOAT,\n",
      "    XSANIN10 TEXT,\n",
      "    SANIN10 INTEGER,\n",
      "    XSANIT10 TEXT,\n",
      "    SANIT10 FLOAT,\n",
      "    XSANIN11 TEXT,\n",
      "    SANIN11 INTEGER,\n",
      "    XSANIT11 TEXT,\n",
      "    SANIT11 FLOAT,\n",
      "    XSANIN12 TEXT,\n",
      "    SANIN12 INTEGER,\n",
      "    XSANIT12 TEXT,\n",
      "    SANIT12 FLOAT,\n",
      "    XSANIN13 TEXT,\n",
      "    SANIN13 INTEGER,\n",
      "    XSANIT13 TEXT,\n",
      "    SANIT13 FLOAT,\n",
      "    XSANIN14 TEXT,\n",
      "    SANIN14 INTEGER,\n",
      "    XSANIT14 TEXT,\n",
      "    SANIT14 FLOAT,\n",
      "    COLLECTION TEXT\n",
      ");\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgallegos5\\AppData\\Local\\Temp\\ipykernel_12336\\864724194.py:9: UserWarning: Pandas Dataframe has non-standard index of type <class 'pandas.core.indexes.base.Index'> which will not be written. Consider changing the index to pd.RangeIndex(start=0,...,step=1) or call reset_index() to keep index as column(s)\n",
      "  pt.write_pandas(conn=con, df=unioned_df, table_name=table_name, database='IPEDS_DEV', schema='IPEDS_ALL_YEARS')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key in regex_names:\n",
    "    unioned_df = union_file_years(regex_names[key])\n",
    "    unioned_df.columns = strip_spaces(unioned_df.columns) \n",
    "    table_name = key.upper()\n",
    "    create_table_sql = generate_sql_create_table(unioned_df, table_name)\n",
    "    print('Creating table {}'.format(table_name))\n",
    "    print(create_table_sql)\n",
    "    cur.execute(create_table_sql)\n",
    "    pt.write_pandas(conn=con, df=unioned_df, table_name=table_name, database='IPEDS_DEV', schema='IPEDS_ALL_YEARS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
